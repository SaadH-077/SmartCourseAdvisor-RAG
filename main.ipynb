{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader, CSVLoader, Docx2txtLoader\n",
    "from pathlib import Path\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from langchain.memory import ConversationSummaryBufferMemory,ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_VECTOR_STORE_DIR = Path('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_document_loader(TMP_DIR):\n",
    "    \"\"\"\n",
    "    Load documents from the temporary directory (TMP_DIR). \n",
    "    Files can be in txt, pdf, CSV or docx format.\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # txt_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(txt_loader.load())\n",
    "\n",
    "    # pdf_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.pdf\", loader_cls=PyPDFLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(pdf_loader.load())\n",
    "\n",
    "    # csv_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.csv\", loader_cls=CSVLoader, show_progress=True,\n",
    "    #     loader_kwargs={\"encoding\":\"utf8\"}\n",
    "    # )\n",
    "    # documents.extend(csv_loader.load())\n",
    "\n",
    "    doc_loader = DirectoryLoader(\n",
    "        TMP_DIR.as_posix(),\n",
    "        glob=\"**/*.docx\",\n",
    "        loader_cls=Docx2txtLoader,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    documents.extend(doc_loader.load())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 1201.92it/s]\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'course reviews'\n",
    "TMP_DIR = Path(directory_path)\n",
    "documents = langchain_document_loader(TMP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Year of study: Senior\\n\\nReview for 100 level course:\\n\\nCS100 - Computational Problem Solving\\nThis is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\\n\\nGpa: 3.60-4.00' metadata={'source': 'course reviews/Student_10_Course_100.docx'}\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_embedding_model():\n",
    "    embedding = OllamaEmbeddings(model='nomic-embed-text' , show_progress = True)\n",
    "    return embedding\n",
    "\n",
    "embeddings_nomic = select_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(embeddings,documents,vectorstore_name):\n",
    "    \"\"\"Create a Chroma vector database.\"\"\"\n",
    "    persist_directory = (LOCAL_VECTOR_STORE_DIR.as_posix() + \"/\" + vectorstore_name)\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 54.39it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 45.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of sentences (0, 1): 331.183\n",
      "Similarty of sentences (0, 2): 120.802\n",
      "Similarty of sentences (1, 2): 170.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\"I like pets.\",\n",
    "             \"Pets bring joy to our lives.\",\n",
    "             \"Langchain is a framework for developing applications powered by LLMs.\"]\n",
    "# 1. Calculate embedding vectors\n",
    "embedding_vectors = [embeddings_nomic.embed_query(sentence) for sentence in sentences]\n",
    "\n",
    "for combination in list(combinations(range(len(sentences)),2)):\n",
    "    # 2. Calculate similarity using dot product from numpy:\n",
    "    dot_prodduct = round(np.dot(embedding_vectors[combination[0]], embedding_vectors[combination[1]]),3)\n",
    "    print(f\"Similarty of sentences {combination}: {dot_prodduct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vectorstores = False # change to True to create vectorstores\n",
    "\n",
    "if create_vectorstores:\n",
    "    vector_store_nomic = create_vectorstore(embeddings_nomic,documents,\"vector_store_nomic\")\n",
    "    print(\"Vector store created\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_store_Ollama: 67 chunks.\n"
     ]
    }
   ],
   "source": [
    "vector_store_nomic = Chroma(persist_directory = LOCAL_VECTOR_STORE_DIR.as_posix() + \"/vector_store_nomic\", \n",
    "                            embedding_function=embeddings_nomic)\n",
    "print(\"vector_store_Ollama:\",vector_store_nomic._collection.count(),\"chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_documents(docs,search_with_score=False):\n",
    "    \"\"\"helper function to print documents.\"\"\"\n",
    "    if search_with_score:\n",
    "        # used for similarity_search_with_score\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc[0].page_content +\"\\n\\nscore:\"+str(round(doc[-1],3))+\"\\n\" \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # used for similarity_search or max_marginal_relevance_search\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc.page_content \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:375.421\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "CS100 - Computational Problem Solving\n",
      "This is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:401.399\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "Cs-100, can look very intimidating if you don't have an interest in computer science but if you just try to be a little curious and practice the assignments, then it's actually pretty easy. I got an F first time I took this course, but after putting in a little effort, I got an A-.\n",
      "\n",
      "Gpa: 2.50-3.00\n",
      "\n",
      "score:406.734\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "CS 100. Really good course. Provided the basics of programming and built a steady development in creating algorithms. Introduced basics concepts and required students to present thorough understanding of what is required in coding design and algorithms\n",
      "\n",
      "Gpa: 3.30-3.60\n",
      "\n",
      "score:419.392\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get most similar documents - with scores \n",
    "# Here, we use Cosine Similarity. So a lower score is better.\n",
    "\n",
    "query = 'What are some difficult CS courses?'\n",
    "docs_withScores = vector_store_nomic.similarity_search_with_score(query,k=4)\n",
    "\n",
    "print_documents(docs_withScores,search_with_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████| 4/4 [00:00<00:00, 24.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of document_0 to the query: 190.1073\n",
      "Similarty of document_1 to the query: 212.1687\n",
      "Similarty of document_2 to the query: 208.5819\n",
      "Similarty of document_3 to the query: 204.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = embeddings_nomic.embed_query(query)\n",
    "docs_embeddings = embeddings_nomic.embed_documents(\n",
    "    [docs_withScores[i][0].page_content \n",
    "     for i in range(len(docs_withScores))\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i in range(len(docs_embeddings)):\n",
    "    dot_product = round(np.dot(query_embeddings, docs_embeddings[i]),4)\n",
    "    print(f\"Similarty of document_{i} to the query: {dot_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorstore_backed_retriever(vectorstore,search_type=\"similarity\",k=4,score_threshold=None):\n",
    "    \"\"\"create a vectorsore-backed retriever\n",
    "    Parameters: \n",
    "        search_type: Defines the type of search that the Retriever should perform.\n",
    "            Can be \"similarity\" (default), \"mmr\", or \"similarity_score_threshold\"\n",
    "        k: number of documents to return (Default: 4) \n",
    "        score_threshold: Minimum relevance threshold for similarity_score_threshold (default=None)\n",
    "    \"\"\"\n",
    "    search_kwargs={}\n",
    "    if k is not None:\n",
    "        search_kwargs['k'] = k\n",
    "    if score_threshold is not None:\n",
    "        search_kwargs['score_threshold'] = score_threshold\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=search_type,\n",
    "        search_kwargs=search_kwargs\n",
    "    )\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 400 level course:\n",
      "\n",
      "CA 437 - Deep Learrning. Intellectually challenging and stimulating. Dl introduces the many used practical applications of different algorithms. The course, up until now, has thoroughly tested our understanding of different concepts and its application in coding. Very good and practical course\n",
      "\n",
      "Gpa: 3.30-3.60\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "Review for 300 level course:\n",
      "\n",
      "Feedback Control Systems\n",
      "This course introduced us to the idea of feedback signals and looped mechanisms. With widespread usage within the industry, the course focused on instikkimg state of the art mechanisms for dynamic control of various machines such as robots, electrical equipments etc.\n",
      "I had an A in this course \n",
      "The course difficulty was 3\n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "Econ 100\n",
      "Econ 100 is one of the most fun, intuitive course I took. It gives insights into the world if economics without overwhelming the students. The course delved into some basic Economic models, their applications. The graded instruments were nicely segmented with a well defined outline. The instructor, though some times can feel very standoffish, is no doubt a great instructor if not great human.\n",
      "\n",
      "Gpa: 3.60-4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Similarity search\n",
    "retriever = Vectorstore_backed_retriever(vector_store_nomic,search_type=\"similarity\",k=4)\n",
    "\n",
    "# Get relevant documents\n",
    "\n",
    "query = 'What are some intellectually challenging and stimulating courses?'\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "print_documents(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory(model_name='gpt-3.5-turbo',memory_max_token=None):\n",
    "    \"\"\"Creates a ConversationSummaryBufferMemory for gpt-3.5-turbo\n",
    "    Creates a ConversationBufferMemory for the other models.\"\"\"\n",
    "    \n",
    "    if model_name==\"gpt-3.5-turbo\":\n",
    "        if memory_max_token is None:\n",
    "            memory_max_token = 1024 # max_tokens for 'gpt-3.5-turbo' = 4096\n",
    "        memory = ConversationSummaryBufferMemory(\n",
    "            max_token_limit=memory_max_token,\n",
    "            llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\",openai_api_key=openai_api_key,temperature=0.1),\n",
    "            return_messages=True,\n",
    "            memory_key='chat_history',\n",
    "            output_key=\"answer\",\n",
    "            input_key=\"question\"\n",
    "        )\n",
    "    else:\n",
    "        memory = ConversationBufferMemory(\n",
    "            return_messages=True,\n",
    "            memory_key='chat_history',\n",
    "            output_key=\"answer\",\n",
    "            input_key=\"question\",\n",
    "        )  \n",
    "    return memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
