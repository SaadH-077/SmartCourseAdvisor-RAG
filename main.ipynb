{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader, CSVLoader, Docx2txtLoader\n",
    "from pathlib import Path\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from langchain.memory import ConversationSummaryBufferMemory,ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_retrieval_chain, RetrievalQA, ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n",
    "import google.generativeai as genai\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_VECTOR_STORE_DIR = Path('./data')\n",
    "GOOGLE_API_KEY = \"AIzaSyDzH-2ryBkzhrWtKJ6NmBRLREpmLsf8FqE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_document_loader(TMP_DIR):\n",
    "    \"\"\"\n",
    "    Load documents from the temporary directory (TMP_DIR). \n",
    "    Files can be in txt, pdf, CSV or docx format.\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # txt_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(txt_loader.load())\n",
    "\n",
    "    # pdf_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.pdf\", loader_cls=PyPDFLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(pdf_loader.load())\n",
    "\n",
    "    # csv_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.csv\", loader_cls=CSVLoader, show_progress=True,\n",
    "    #     loader_kwargs={\"encoding\":\"utf8\"}\n",
    "    # )\n",
    "    # documents.extend(csv_loader.load())\n",
    "\n",
    "    doc_loader = DirectoryLoader(\n",
    "        TMP_DIR.as_posix(),\n",
    "        glob=\"**/*.docx\",\n",
    "        loader_cls=Docx2txtLoader,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    documents.extend(doc_loader.load())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 1605.22it/s]\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'course reviews'\n",
    "TMP_DIR = Path(directory_path)\n",
    "documents = langchain_document_loader(TMP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Year of study: Senior\\n\\nReview for 100 level course:\\n\\nCS100 - Computational Problem Solving\\nThis is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\\n\\nGpa: 3.60-4.00' metadata={'source': 'course reviews/Student_10_Course_100.docx'}\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_embedding_model():\n",
    "    embedding = OllamaEmbeddings(model='nomic-embed-text')\n",
    "    return embedding\n",
    "\n",
    "embeddings_nomic = select_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(embeddings,documents,vectorstore_name):\n",
    "    \"\"\"Create a Chroma vector database.\"\"\"\n",
    "    persist_directory = (LOCAL_VECTOR_STORE_DIR.as_posix() + \"/\" + vectorstore_name)\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of sentences (0, 1): 331.183\n",
      "Similarty of sentences (0, 2): 120.802\n",
      "Similarty of sentences (1, 2): 170.24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\"I like pets.\",\n",
    "             \"Pets bring joy to our lives.\",\n",
    "             \"Langchain is a framework for developing applications powered by LLMs.\"]\n",
    "# 1. Calculate embedding vectors\n",
    "embedding_vectors = [embeddings_nomic.embed_query(sentence) for sentence in sentences]\n",
    "\n",
    "for combination in list(combinations(range(len(sentences)),2)):\n",
    "    # 2. Calculate similarity using dot product from numpy:\n",
    "    dot_prodduct = round(np.dot(embedding_vectors[combination[0]], embedding_vectors[combination[1]]),3)\n",
    "    print(f\"Similarty of sentences {combination}: {dot_prodduct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vectorstores = False # change to True to create vectorstores\n",
    "\n",
    "if create_vectorstores:\n",
    "    vector_store_nomic = create_vectorstore(embeddings_nomic,documents,\"vector_store_nomic\")\n",
    "    print(\"Vector store created\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_store_Ollama: 134 chunks.\n"
     ]
    }
   ],
   "source": [
    "vector_store_nomic = Chroma(persist_directory = LOCAL_VECTOR_STORE_DIR.as_posix() + \"/vector_store_nomic\", \n",
    "                            embedding_function=embeddings_nomic)\n",
    "print(\"vector_store_Ollama:\",vector_store_nomic._collection.count(),\"chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_documents(docs,search_with_score=False):\n",
    "    \"\"\"helper function to print documents.\"\"\"\n",
    "    if search_with_score:\n",
    "        # used for similarity_search_with_score\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc[0].page_content +\"\\n\\nscore:\"+str(round(doc[-1],3))+\"\\n\" \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # used for similarity_search or max_marginal_relevance_search\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc.page_content \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:375.421\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:375.421\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "CS100 - Computational Problem Solving\n",
      "This is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:401.399\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "CS100 - Computational Problem Solving\n",
      "This is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:401.399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get most similar documents - with scores \n",
    "# Here, we use Cosine Similarity. So a lower score is better.\n",
    "\n",
    "query = 'What are some difficult CS courses?'\n",
    "docs_withScores = vector_store_nomic.similarity_search_with_score(query,k=4)\n",
    "\n",
    "print_documents(docs_withScores,search_with_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of document_0 to the query: 190.1073\n",
      "Similarty of document_1 to the query: 190.1073\n",
      "Similarty of document_2 to the query: 212.1687\n",
      "Similarty of document_3 to the query: 212.1687\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = embeddings_nomic.embed_query(query)\n",
    "docs_embeddings = embeddings_nomic.embed_documents(\n",
    "    [docs_withScores[i][0].page_content \n",
    "     for i in range(len(docs_withScores))\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i in range(len(docs_embeddings)):\n",
    "    dot_product = round(np.dot(query_embeddings, docs_embeddings[i]),4)\n",
    "    print(f\"Similarty of document_{i} to the query: {dot_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorstore_backed_retriever(vectorstore,search_type=\"similarity\",k=4,score_threshold=None):\n",
    "    \"\"\"create a vectorsore-backed retriever\n",
    "    Parameters: \n",
    "        search_type: Defines the type of search that the Retriever should perform.\n",
    "            Can be \"similarity\" (default), \"mmr\", or \"similarity_score_threshold\"\n",
    "        k: number of documents to return (Default: 4) \n",
    "        score_threshold: Minimum relevance threshold for similarity_score_threshold (default=None)\n",
    "    \"\"\"\n",
    "    search_kwargs={}\n",
    "    if k is not None:\n",
    "        search_kwargs['k'] = k\n",
    "    if score_threshold is not None:\n",
    "        search_kwargs['score_threshold'] = score_threshold\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=search_type,\n",
    "        search_kwargs=search_kwargs\n",
    "    )\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 400 level course:\n",
      "\n",
      "CA 437 - Deep Learrning. Intellectually challenging and stimulating. Dl introduces the many used practical applications of different algorithms. The course, up until now, has thoroughly tested our understanding of different concepts and its application in coding. Very good and practical course\n",
      "\n",
      "Gpa: 3.30-3.60\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 400 level course:\n",
      "\n",
      "CA 437 - Deep Learrning. Intellectually challenging and stimulating. Dl introduces the many used practical applications of different algorithms. The course, up until now, has thoroughly tested our understanding of different concepts and its application in coding. Very good and practical course\n",
      "\n",
      "Gpa: 3.30-3.60\n"
     ]
    }
   ],
   "source": [
    "# Similarity search\n",
    "retriever = Vectorstore_backed_retriever(vector_store_nomic,search_type=\"similarity\",k=4)\n",
    "\n",
    "# Get relevant documents\n",
    "\n",
    "query = 'What are some intellectually challenging and stimulating courses?'\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "print_documents(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_LLM(api_key,temperature=0.5,top_p=0.95,model_name=None):\n",
    "    \"\"\"Instantiate LLM in Langchain.\n",
    "    Parameters:\n",
    "        LLM_provider (str): the LLM provider; in [\"OpenAI\",\"Google\",\"HuggingFace\"]\n",
    "        model_name (str): in [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-0125\", \"gpt-4-turbo-preview\", \n",
    "            \"gemini-pro\", \"mistralai/Mistral-7B-Instruct-v0.2\"].            \n",
    "        api_key (str): google_api_key or openai_api_key or huggingfacehub_api_token \n",
    "        temperature (float): Range: 0.0 - 1.0; default = 0.5\n",
    "        top_p (float): : Range: 0.0 - 1.0; default = 1.\n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "        # repo_id=model_name,\n",
    "        huggingfacehub_api_token=api_key,\n",
    "        model_kwargs={\n",
    "            \"temperature\":temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"do_sample\": True,\n",
    "            \"max_new_tokens\":1024\n",
    "        },\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm = instantiate_LLM(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory():\n",
    "    \"\"\"Creates a ConversationSummaryBufferMemory for our model\n",
    "    Creates a ConversationBufferWindowMemory for our models.\"\"\"\n",
    "    \n",
    "    memory = ConversationBufferWindowMemory(\n",
    "        memory_key=\"history\",\n",
    "        input_key=\"question\",\n",
    "        return_messages=True,\n",
    "        k=3\n",
    "    )\n",
    "\n",
    "    return memory\n",
    "\n",
    "memory = create_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"question\": \"What can you do?\"},\n",
    "    {\"output\": \"I can answer queries based on the past reviews and course outlines of various courses offered at LUMS.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_qa = \"\"\"\n",
    "You are a professional chatbot assistant for helping students at LUMS regarding course selection.\n",
    "\n",
    "Please follow the following rules:\n",
    "\n",
    "1. Answer the question in your own words from the context given to you.\n",
    "2. If you don't know the answer, don't try to make up an answer.\n",
    "3. If you don't have a course's review or outline, just say that you do not know about this course.\n",
    "4. If a user enters a course code (e.g. ECON100 or CS370), match it with reviews with that course code. If the user enters a course name (e.g. Introduction to Economics or Database Systems), match it with reviews with that course name.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "You are having a converation with a student at LUMS.\n",
    "\n",
    "Chat History: {history}\n",
    "\n",
    "Human: {question}\n",
    "\n",
    "Assistant123:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=context_qa\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    verbose=False,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": memory\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  .  .  .   \n",
      "Me: Should i take the course with code REL500\n",
      "Chatbot: \n",
      "I'm sorry for any confusion, but I don't have a review or outline for the course with code REL500. Could you please provide more details about the course, such as its name or a brief description, so I can try to help you with any related queries?\n",
      "  .  .  .   \n",
      "Me: should i take REL523\n",
      "Chatbot: \n",
      "I'm unable to provide information about the course REL523 as I don't have any reviews or outlines related to it in my database. Could you please check the course name or code with your academic advisor or the department offering the course for more accurate and detailed information?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/93/p8_82pyd6nxg7_p_xtp6xv100000gn/T/ipykernel_57259/2978624241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your question here (or type 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exiting ChatBot. Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your question here (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting ChatBot. Goodbye!\")\n",
    "        break\n",
    "    print(\"  .  .  .   \")\n",
    "    #result = agent(user_input)\n",
    "\n",
    "    result = qa({'query': user_input})\n",
    "\n",
    "    # print(\"result:\", result)\n",
    "\n",
    "    answer = result['result']\n",
    "\n",
    "    # only keep the part followed by 'Assistant123:'\n",
    "    answer = answer.split('Assistant123:')[-1]\n",
    "    print(\"Me:\", user_input)\n",
    "    print(\"Chatbot:\", answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
