{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader, CSVLoader, Docx2txtLoader\n",
    "from pathlib import Path\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from langchain.memory import ConversationSummaryBufferMemory,ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_retrieval_chain, RetrievalQA, ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n",
    "import google.generativeai as genai\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_VECTOR_STORE_DIR = Path('./data')\n",
    "GOOGLE_API_KEY = \"AIzaSyDzH-2ryBkzhrWtKJ6NmBRLREpmLsf8FqE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_document_loader(TMP_DIR):\n",
    "    \"\"\"\n",
    "    Load documents from the temporary directory (TMP_DIR). \n",
    "    Files can be in txt, pdf, CSV or docx format.\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # txt_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(txt_loader.load())\n",
    "\n",
    "    # pdf_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.pdf\", loader_cls=PyPDFLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(pdf_loader.load())\n",
    "\n",
    "    # csv_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.csv\", loader_cls=CSVLoader, show_progress=True,\n",
    "    #     loader_kwargs={\"encoding\":\"utf8\"}\n",
    "    # )\n",
    "    # documents.extend(csv_loader.load())\n",
    "\n",
    "    doc_loader = DirectoryLoader(\n",
    "        TMP_DIR.as_posix(),\n",
    "        glob=\"**/*.docx\",\n",
    "        loader_cls=Docx2txtLoader,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    documents.extend(doc_loader.load())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 1786.48it/s]\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'course reviews'\n",
    "TMP_DIR = Path(directory_path)\n",
    "documents = langchain_document_loader(TMP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Year of study: Senior\\n\\nReview for 100 level course:\\n\\nCS100 - Computational Problem Solving\\nThis is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\\n\\nGpa: 3.60-4.00' metadata={'source': 'course reviews/Student_10_Course_100.docx'}\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_embedding_model():\n",
    "    embedding = OllamaEmbeddings(model='nomic-embed-text')\n",
    "    return embedding\n",
    "\n",
    "embeddings_nomic = select_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(embeddings,documents,vectorstore_name):\n",
    "    \"\"\"Create a Chroma vector database.\"\"\"\n",
    "    persist_directory = (LOCAL_VECTOR_STORE_DIR.as_posix() + \"/\" + vectorstore_name)\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of sentences (0, 1): 331.183\n",
      "Similarty of sentences (0, 2): 120.802\n",
      "Similarty of sentences (1, 2): 170.24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\"I like pets.\",\n",
    "             \"Pets bring joy to our lives.\",\n",
    "             \"Langchain is a framework for developing applications powered by LLMs.\"]\n",
    "# 1. Calculate embedding vectors\n",
    "embedding_vectors = [embeddings_nomic.embed_query(sentence) for sentence in sentences]\n",
    "\n",
    "for combination in list(combinations(range(len(sentences)),2)):\n",
    "    # 2. Calculate similarity using dot product from numpy:\n",
    "    dot_prodduct = round(np.dot(embedding_vectors[combination[0]], embedding_vectors[combination[1]]),3)\n",
    "    print(f\"Similarty of sentences {combination}: {dot_prodduct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vectorstores = False # change to True to create vectorstores\n",
    "\n",
    "if create_vectorstores:\n",
    "    vector_store_nomic = create_vectorstore(embeddings_nomic,documents,\"vector_store_nomic\")\n",
    "    print(\"Vector store created\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_store_Ollama: 67 chunks.\n"
     ]
    }
   ],
   "source": [
    "vector_store_nomic = Chroma(persist_directory = LOCAL_VECTOR_STORE_DIR.as_posix() + \"/vector_store_nomic\", \n",
    "                            embedding_function=embeddings_nomic)\n",
    "print(\"vector_store_Ollama:\",vector_store_nomic._collection.count(),\"chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_documents(docs,search_with_score=False):\n",
    "    \"\"\"helper function to print documents.\"\"\"\n",
    "    if search_with_score:\n",
    "        # used for similarity_search_with_score\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc[0].page_content +\"\\n\\nscore:\"+str(round(doc[-1],3))+\"\\n\" \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # used for similarity_search or max_marginal_relevance_search\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc.page_content \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:375.421\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "CS100 - Computational Problem Solving\n",
      "This is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:401.399\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "Cs-100, can look very intimidating if you don't have an interest in computer science but if you just try to be a little curious and practice the assignments, then it's actually pretty easy. I got an F first time I took this course, but after putting in a little effort, I got an A-.\n",
      "\n",
      "Gpa: 2.50-3.00\n",
      "\n",
      "score:406.734\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "CS 100. Really good course. Provided the basics of programming and built a steady development in creating algorithms. Introduced basics concepts and required students to present thorough understanding of what is required in coding design and algorithms\n",
      "\n",
      "Gpa: 3.30-3.60\n",
      "\n",
      "score:419.392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get most similar documents - with scores \n",
    "# Here, we use Cosine Similarity. So a lower score is better.\n",
    "\n",
    "query = 'What are some difficult CS courses?'\n",
    "docs_withScores = vector_store_nomic.similarity_search_with_score(query,k=4)\n",
    "\n",
    "print_documents(docs_withScores,search_with_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of document_0 to the query: 190.1073\n",
      "Similarty of document_1 to the query: 212.1687\n",
      "Similarty of document_2 to the query: 208.5819\n",
      "Similarty of document_3 to the query: 204.6471\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = embeddings_nomic.embed_query(query)\n",
    "docs_embeddings = embeddings_nomic.embed_documents(\n",
    "    [docs_withScores[i][0].page_content \n",
    "     for i in range(len(docs_withScores))\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i in range(len(docs_embeddings)):\n",
    "    dot_product = round(np.dot(query_embeddings, docs_embeddings[i]),4)\n",
    "    print(f\"Similarty of document_{i} to the query: {dot_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorstore_backed_retriever(vectorstore,search_type=\"similarity\",k=4,score_threshold=None):\n",
    "    \"\"\"create a vectorsore-backed retriever\n",
    "    Parameters: \n",
    "        search_type: Defines the type of search that the Retriever should perform.\n",
    "            Can be \"similarity\" (default), \"mmr\", or \"similarity_score_threshold\"\n",
    "        k: number of documents to return (Default: 4) \n",
    "        score_threshold: Minimum relevance threshold for similarity_score_threshold (default=None)\n",
    "    \"\"\"\n",
    "    search_kwargs={}\n",
    "    if k is not None:\n",
    "        search_kwargs['k'] = k\n",
    "    if score_threshold is not None:\n",
    "        search_kwargs['score_threshold'] = score_threshold\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=search_type,\n",
    "        search_kwargs=search_kwargs\n",
    "    )\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 400 level course:\n",
      "\n",
      "CA 437 - Deep Learrning. Intellectually challenging and stimulating. Dl introduces the many used practical applications of different algorithms. The course, up until now, has thoroughly tested our understanding of different concepts and its application in coding. Very good and practical course\n",
      "\n",
      "Gpa: 3.30-3.60\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "Review for 300 level course:\n",
      "\n",
      "Feedback Control Systems\n",
      "This course introduced us to the idea of feedback signals and looped mechanisms. With widespread usage within the industry, the course focused on instikkimg state of the art mechanisms for dynamic control of various machines such as robots, electrical equipments etc.\n",
      "I had an A in this course \n",
      "The course difficulty was 3\n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 100 level course:\n",
      "\n",
      "Econ 100\n",
      "Econ 100 is one of the most fun, intuitive course I took. It gives insights into the world if economics without overwhelming the students. The course delved into some basic Economic models, their applications. The graded instruments were nicely segmented with a well defined outline. The instructor, though some times can feel very standoffish, is no doubt a great instructor if not great human.\n",
      "\n",
      "Gpa: 3.60-4.00\n"
     ]
    }
   ],
   "source": [
    "# Similarity search\n",
    "retriever = Vectorstore_backed_retriever(vector_store_nomic,search_type=\"similarity\",k=4)\n",
    "\n",
    "# Get relevant documents\n",
    "\n",
    "query = 'What are some intellectually challenging and stimulating courses?'\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "print_documents(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_LLM(api_key,temperature=0.5,top_p=0.95,model_name=None):\n",
    "    \"\"\"Instantiate LLM in Langchain.\n",
    "    Parameters:\n",
    "        LLM_provider (str): the LLM provider; in [\"OpenAI\",\"Google\",\"HuggingFace\"]\n",
    "        model_name (str): in [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-0125\", \"gpt-4-turbo-preview\", \n",
    "            \"gemini-pro\", \"mistralai/Mistral-7B-Instruct-v0.2\"].            \n",
    "        api_key (str): google_api_key or openai_api_key or huggingfacehub_api_token \n",
    "        temperature (float): Range: 0.0 - 1.0; default = 0.5\n",
    "        top_p (float): : Range: 0.0 - 1.0; default = 1.\n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "        # repo_id=model_name,\n",
    "        huggingfacehub_api_token=api_key,\n",
    "        model_kwargs={\n",
    "            \"temperature\":temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"do_sample\": True,\n",
    "            \"max_new_tokens\":1024\n",
    "        },\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm = instantiate_LLM(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory():\n",
    "    \"\"\"Creates a ConversationSummaryBufferMemory for our model\n",
    "    Creates a ConversationBufferWindowMemory for our models.\"\"\"\n",
    "    \n",
    "    memory = ConversationBufferWindowMemory(\n",
    "        memory_key=\"history\",\n",
    "        input_key=\"question\",\n",
    "        return_messages=True,\n",
    "        k=3\n",
    "    )\n",
    "\n",
    "    return memory\n",
    "\n",
    "memory = create_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"question\": \"What can you do?\"},\n",
    "    {\"output\": \"I can answer queries based on the past reviews and course outlines of various courses offered at LUMS.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_qa = \"\"\"\n",
    "You are a professional chatbot assistant for helping students at LUMS regarding course selection.\n",
    "\n",
    "Please follow the following rules:\n",
    "\n",
    "1. Answer the question in your own words from the context given to you.\n",
    "2. If you don't know the answer, don't try to make up an answer.\n",
    "3. If you don't have a course's review or outline, just say that you do not know about this course.\n",
    "4. If a user enters a course code (e.g. ECON100 or CS370), match it with reviews with that course code. If the user enters a course name (e.g. Introduction to Economics or Database Systems), match it with reviews with that course name.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "You are having a converation with a student at LUMS.\n",
    "\n",
    "Chat History: {history}\n",
    "\n",
    "Human: {question}\n",
    "\n",
    "Assistant123:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=context_qa\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    verbose=False,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": memory\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/gradio/analytics.py:100: UserWarning: unable to parse version details from package URL.\n",
      "  warnings.warn(\"unable to parse version details from package URL.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def rag_model(query):\n",
    "    # Your RAG model code here\n",
    "    result = qa({'query': query})\n",
    "\n",
    "    # Extract the answer from the result\n",
    "    answer = result['result']\n",
    "\n",
    "    # Extract the response from the answer (if needed)\n",
    "    response = answer.split('Assistant123:')[-1]\n",
    "\n",
    "    return response\n",
    "\n",
    "iface = gr.Interface(fn=rag_model, inputs=\"text\", outputs=\"text\", title=\"RAG Model\")\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
